---
title: "An overview of `BradleyTerryScalable`" 
format: 
  revealjs:
    theme: emk-theme.scss
    highlight-style: ek_syntax_highlighting.theme
    execute:
      echo: true
editor: visual
---

## The Bradley-Terry model {.middle .center background-color="#006AD4"}

##  {background-image="images/football.png" background-size="contain"}

##  {background-image="images/journals.png"}

## The model

The Bradley-Terry probability that item $i$ beats item $j$ is

$$p_{ij} = \frac{\pi_i}{\pi_i + \pi_j},$$

where $\pi_k$ is a strength parameter for player $k$, $1 \leq k \leq K$ and $\sum_{i=1}^K{\pi_i} = K$.

## The comparison graph

![](toy-data-graph.svg){fig-align="center"}

. . .

<br/>**The MLE exists and is finite whenever the comparison graph is fully connected.**

## Fitting the model

::: columns
::: {.column width="50%"}
**MLE**

$$\pi_i^{(n+1)} = \frac{W_i}{\sum_{j=1}^K \frac{n_{ij}}{\pi_i^{(n)} + \pi_j^{(n)}}}$$
:::

::: {.column width="50%"}
**MAP**

$$\pi_i^{(n+1)} = \frac{a - 1 + W_i}{b + \sum_{j=1}^K \frac{n_{ij}}{\pi_i^{(n)} + \pi_j^{(n)}}}
$$
:::
:::

## Fitting the model

::: columns
::: {.column width="50%"}
**MLE**

$$\pi_i^{(n+1)} = \frac{W_i}{\sum_{j=1}^K \frac{n_{ij}}{\pi_i^{(n)} + \pi_j^{(n)}}}$$
:::

::: {.column width="50%"}
**MAP**

$$\pi_i^{(n+1)} = \frac{{\color{#D4006A}{a - 1}} + W_i}{{\color{#D4006A}b} + \sum_{j=1}^K \frac{n_{ij}}{\pi_i^{(n)} + \pi_j^{(n)}}}
$$
:::
:::

## `BradleyTerryScalable` {.middle .center background-color="#006AD4"}

## Aims

- Fit the Bradley-Terry model to large and (potentially) sparse data sets

- Has to be fast *enough* ('Scalable' is in the package name!)

- Has to be able to deal with cases when the comparison graph is not fully connected

- Well thought out user interface

- Complement to (NOT a replacement for) `BradleyTerry2` package

## Workflow: data

- `btdata(x)` to create object of class `"btdata"`

  - `x` can be a data frame, graph, matrix or contigency table
  
  - may need to call `codes_to_counts()` first

  - `summary(btdata)`
  
  - `select_components(btdata, subset)`

## Workflow: fit

- `btfit(btdata, a)` to fit model and create object of class `"btfit"`

  - S3 methods for `btfit` object: 
      - `summary`, `fitted`, `coef`, `vcov`, `simulate`
      
  - `btprob(object)` for Bradley-Terry probabilities $p_{ij}$

## `btdata(x)`

```{r citations}
library(BradleyTerryScalable)
citations
```

```{r}
citations_btdata <- btdata(citations)
summary(citations_btdata) 
```
## {.smaller75}

```{r toy-data}
toy_data
```
##

```{r toy-btdata}
#| warning: false
toy_btdata <- toy_data |>
  codes_to_counts(c("W1", "W2", "D")) |>
  btdata()
summary(toy_btdata)
```

## `btfit(btdata, a)`

```{r btfit-noeval}
#| eval: false
btfit(btdata, a) 
```

- If `a = 1`, finds MLE on each fully connected component, using the MM-algorithm

- If `a > 1`, finds the MAP estimate of $\pi$

- Returns a `btfit` S3 object

. . .

```{r btfit-full-noeval}
#| eval: false
btfit(btdata, a, 
      MAP_by_component = FALSE, 
      subset = NULL, 
      maxit = 10000, 
      epsilon = 0.001) 
```
## {.smaller75}

```{r toy-map}
toy_fit_MAP <- btfit(toy_btdata, a = 1.1)
summary(toy_fit_MAP)  
```

## {.smaller75}

```{r toy-mle}
toy_fit_MLE <- btfit(toy_btdata, a = 1)
summary(toy_fit_MLE, SE = TRUE) 
```

## {.smaller75}

```{r toy-subset}
toy_data |>
  codes_to_counts(c("W1", "W2", "D")) |>
  btdata() |>
  btfit(1) |>
  summary(ref = "Amy", subset = function(x) "Amy" %in% names(x)) 
```
## `btprob(object)`

Gives the Bradley-Terry probabilities $\frac{\pi_i}{\pi_i + \pi_j}$

```{r citations-prob}
#| code-line-numbers: "4"

citations |>
  btdata() |>
  btfit(1) |>
  btprob() |>
  round(3)
```

## `btprob(object)`

Gives the Bradley-Terry probabilities $\frac{\pi_i}{\pi_i + \pi_j}$

```{r citations-prob-df}
#| code-line-numbers: "4"

citations |>
  btdata() |>
  btfit(1) |>
  btprob(as_df = TRUE)
```

## A real-world example

```{r load_comp_cites}
#| cache: true
#| echo: false
#| message: false
#| warning: false

library(dplyr)

comp_cites <- readr::read_csv(here::here("comp_cites_3.csv")) %>%
  mutate(cited_pdpass = as.character(cited_pdpass), citing_pdpass = as.character(citing_pdpass))
```

```{r}
comp_cites
```

## btdata: timing

```{r btdata-timing}
#| cache: true
system.time(comp_cites_data <- btdata(comp_cites))
summary(comp_cites_data)
```
## btfit: timing
```{r btfit-timing}
#| cache: true
system.time(comp_cites_fit_mle <- btfit(comp_cites_data, 1))
system.time(comp_cites_fit_map <- btfit(comp_cites_data, 1.1)) 
```

## btfit() timing simulations

Time in seconds to run `btfit()` given number of items and win matrix densities <b style="color:#00D4D4;">0.5</b>, <b style="color:#006AD4;">0.1</b>, <b style="color:#00D46A;">0.01</b> and <b style="color:#D4006A;">0.001</b>.



```{r}
#| echo: false

load("btfit_timings_df.RData")

library(ggplot2)
library(ggrepel)

ggplot(btfit_timings_df, aes(K, time, colour = density)) +
  geom_line(size = 1.5) + 
  geom_point(size = 3) +
  xlab(NULL) +
  ylab(NULL) +
  scale_colour_manual(values = c("#D4006A", "#00D46A", "#006AD4", "#00D4D4")) +
  theme_minimal() +
  theme(legend.position = "none",
        axis.text = element_text(size = 24))
```

## To improve

- Allow additional algorithms (would involve rethinking arguments to `btfit`)

- Make function output type-consistent

- Leverage updates in dependent packages

- Additional functions to return summary values

- Write tests

- Fix bugs

- Return to CRAN

## Thank you! {.right}

### Any questions?
